---
layout: about
title: About
subtitle: 
permalink: /

profile:
  align: right
  image: prof_pic.png
  image_circular: false # crops the image to make it circular
  more_info: mirandrom+ghp@pm.me

news: true  # includes a list of news items
latest_posts: false  # includes a list of the newest posts
selected_papers: false # includes a list of papers marked as "selected={true}"
social: true  # includes social icons at the bottom of the page
---

I'm Andrei, a 1st year PhD student at University of Montreal and Mila supervised by <a href="https://mila.quebec/en/person/irina-rish/">Irina Rish</a>, working on mechanistic interpretability and continual learning of language models for scientific texts. Previously, I was a Masters' student in <a href="https://www.cs.mcgill.ca/~jcheung/index.html">Jackie Cheung</a>'s group at McGill University and Mila, with my <a href="/assets/pdf/thesis_mircea_2023_balaur.pdf">thesis</a> on the topic of augmenting language model pretraining with lexical semantics. I also have collaborations with <a href="https://www.mcgill.ca/geography/people-0/sieber">Renee Seiber</a>'s group (applying NLP to social media to support the information needs of crisis managers and affected people during extreme weather events) and <a href="https://www.mcgill.ca/mcisce/yaoyao-fiona-zhao">Yaoyao Fiona Zhao</a>'s group (creating a scientific information extraction system leveraging LLMs to support researchers in literature reviews).

My current research interests center on how language models and machine learning more broadly can effectively support scientists in their research and enable scientific progress. 
I'm currently approaching this from three related angles: (1) mechanistic interpretability to gain insights into how LLMs handle scientific knowledge; (2) inductive biases to improve LLM robustness on scientific domains; and (3) HCI to better understand how LLMs can support scientists in practice. If this interests you, please reach out!